{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW2FtvFQ443v",
        "outputId": "222e114d-1fe3-4a94-97d8-c7930ce0cd89"
      },
      "outputs": [],
      "source": [
        "# unzip dataset\n",
        "!unzip \"dataset_bayam.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "base_dir = './dataset_bayam'\n",
        "\n",
        "# Set seed for reproducibility\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# Membuat ImageDataGenerator untuk pelatihan dan validasi\n",
        "# Digunakan untuk mempersiapkan data augmentasi yang membuat model lebih kuat dan mampu mengenali berbagai variasi gambar.\n",
        "# Data ini kemudian akan digunakan dalam proses pelatihan dan validasi model machine learning.\n",
        "train_datagen = ImageDataGenerator( # Membuat sebuah instance dari kelas ImageDataGenerator yang akan digunakan untuk menghasilkan data gambar dengan augmentasi.\n",
        "    rescale=1./255, # Menormalisasi nilai piksel gambar dari rentang 0-255 menjadi rentang 0-1. Ini dilakukan dengan membagi setiap nilai piksel dengan 255.\n",
        "    rotation_range=20,  # Mengacak rotasi gambar hingga maksimal 20 derajat ke kanan atau kiri. Hal ini membantu model menjadi lebih tahan terhadap variasi rotasi.\n",
        "    width_shift_range=0.2,  # Menggeser gambar secara horizontal (ke kiri atau kanan) hingga maksimal 20% dari lebar gambar asli. Ini membuat model lebih robust terhadap variasi posisi horizontal.\n",
        "    height_shift_range=0.2, # Menggeser gambar secara vertikal (ke atas atau bawah) hingga maksimal 20% dari tinggi gambar asli. Ini membantu model beradaptasi dengan variasi posisi vertikal.\n",
        "    horizontal_flip=True, # Membalik gambar secara horizontal secara acak. Ini berguna untuk menambahkan variasi pada data pelatihan.\n",
        "    shear_range=0.2,  # Menerapkan transformasi shear (kemiringan) pada gambar hingga maksimal 20%. Ini membuat model lebih tahan terhadap distorsi bentuk.\n",
        "    zoom_range=0.2, # Memperbesar atau memperkecil gambar hingga maksimal 20%. Ini membantu model beradaptasi dengan variasi skala.\n",
        "    fill_mode='nearest',  # Menentukan bagaimana piksel yang hilang setelah transformasi (misalnya setelah rotasi atau geseran) akan diisi. Dalam hal ini, piksel akan diisi dengan nilai piksel terdekat.\n",
        "    validation_split=0.2  # membagi 80% untuk pelatiahn dan 20% dari data untuk validasi\n",
        ")\n",
        "\n",
        "# Membuat ImageDataGenerator untuk testing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# membagi data menjadi train dataset dan validation dataset\n",
        "# Generator data pelatihan\n",
        "train_generator = train_datagen.flow_from_directory(  # Fungsi ini membuat generator data dari gambar yang disimpan dalam folder.\n",
        "    base_dir,  # Direktori sumber data\n",
        "    target_size=(320, 320),  # Mengubah resolusi seluruh gambar menjadi 320x320 piksel\n",
        "    batch_size=32,  # Gambar-gambar diambil dalam kelompok (batch) berukuran 32 gambar setiap kali.\n",
        "    class_mode='categorical',  # Karena ini adalah masalah klasifikasi multi-klas\n",
        "    subset='training',  # Subset pelatihan\n",
        "    seed=seed  # Set seed for train generator\n",
        ")\n",
        "\n",
        "# Generator data validasi\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,  # Direktori sumber data\n",
        "    target_size=(320, 320),  # Mengubah resolusi seluruh gambar menjadi 320x320 piksel\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',  # Karena ini adalah masalah klasifikasi multi-klas\n",
        "    subset='validation',  # Subset validasi\n",
        "    seed=seed  # Set seed for train generator\n",
        ")\n",
        "\n",
        "print(\"Ukuran batch training: \", train_generator.samples)\n",
        "print(\"Ukuran batch validation: \", validation_generator.samples)\n",
        "\n",
        "# Load beberapa gambar asli\n",
        "original_images = []\n",
        "for i in range(10):  # Misalnya 10 gambar\n",
        "    img = load_img(train_generator.filepaths[i], target_size=(320, 320)) # load gambar sesuai alamat dan ubah menjadi ukuran 320x320\n",
        "    img = img_to_array(img) / 255.0  # Normalisasi gambar # konversi objek gambar menjadi array numpy dan lakukan normalisasi agar dapat ditampilkan\n",
        "    original_images.append(img)\n",
        "\n",
        "# Ambil satu batch gambar yang sudah dilakukan augmentasi\n",
        "images, labels = next(train_generator)\n",
        "\n",
        "# Fungsi untuk menampilkan gambar\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_images(images_arr):\n",
        "    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip(images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Tampilkan gambar-gambar yang telah di-augmentasi\n",
        "print(\"Sebelum augmentasi: \")\n",
        "plot_images(original_images)\n",
        "\n",
        "# Tampilkan gambar-gambar yang telah di-augmentasi\n",
        "print(\"Hasil augmentasi: \")\n",
        "plot_images(images[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37T3zPZ67095"
      },
      "source": [
        "# 1. Self-made model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Input layer\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), input_shape=(320, 320, 3)),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # Second conv layer\n",
        "    tf.keras.layers.Conv2D(64, (3, 3)),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # Third conv layer\n",
        "    tf.keras.layers.Conv2D(128, (3, 3)),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # Classification layers\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary to verify the configuration\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJthWUEx84eO",
        "outputId": "d67612c7-d2db-4a7d-bd28-9132ace8c476"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
        "\n",
        "# Menginisialisasi callback EarlyStopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    min_delta=0.1,\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    mode='max',\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Latih model dengan model.fit\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
        "    epochs=100,  # Tambahkan epochs jika akurasi model belum optimal\n",
        "    validation_data=validation_generator,  # Menampilkan akurasi pengujian data validasi\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
        "    # callbacks=[early_stopping],\n",
        "    verbose=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisasi Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Menyimpan arsitektur model ke dalam file PNG\n",
        "plot_model(model, to_file='model_architecture_self-made.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "# Menampilkan arsitektur model di notebook Colab\n",
        "from IPython.display import Image\n",
        "Image('model_architecture_self-made.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "nufxfpPh9Zxg",
        "outputId": "59cd1ac2-6499-4368-b70d-f89efcf369bb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot akurasi pelatihan dan validasi\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Menampilkan akurasi terakhir dari data validasi\n",
        "print(\"Akurasi terakhir:\", history.history['accuracy'][-1])\n",
        "print(\"Akurasi validasi terakhir:\", history.history['val_accuracy'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "yNeh6Q_4b-pH",
        "outputId": "b58dea87-29c7-41b0-fa37-ea359b21ae06"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot loss pelatihan dan validasi\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Menampilkan loss terakhir dari data validasi\n",
        "print(\"Loss terakhir:\", history.history['loss'][-1])\n",
        "print(\"Loss validasi terakhir:\", history.history['val_loss'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsibDicK-X8a",
        "outputId": "a6352ca0-4295-4e87-c8c3-860628d5b774"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "\n",
        "# Membuat generator validasi baru tanpa shuffle untuk evaluasi\n",
        "validation_generator_for_evaluation = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(320, 320),\n",
        "    batch_size=32,  # Sesuai dengan batch size sebelumnya\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False  # Penting: non-aktifkan shuffle\n",
        ")\n",
        "\n",
        "# Perbaikan jumlah steps untuk memastikan semua sampel diproses\n",
        "steps = ceil(validation_generator_for_evaluation.samples / validation_generator_for_evaluation.batch_size)\n",
        "\n",
        "# Memprediksi seluruh data validasi dengan perbaikan steps\n",
        "predictions = model.predict(validation_generator_for_evaluation, steps=steps)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Mendapatkan label sebenarnya dari generator\n",
        "true_labels = validation_generator_for_evaluation.classes\n",
        "\n",
        "# Memastikan jumlah prediksi sama dengan label sebenarnya\n",
        "assert predicted_labels.shape[0] == true_labels.shape[0], \"Jumlah prediksi dan label sebenarnya harus sama.\"\n",
        "\n",
        "# Menghitung confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Menghitung metrik lain\n",
        "report = classification_report(true_labels, predicted_labels, target_names=validation_generator_for_evaluation.class_indices.keys())\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Menampilkan class indices\n",
        "class_indices = validation_generator_for_evaluation.class_indices\n",
        "print(\"Class indices:\", class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "98O-c6pb-kBW",
        "outputId": "99c7d895-a7f8-4e85-bcfb-0feff9094840"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Menampilkan confusion matrix sebagai heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Karat Putih', 'Kekurangan Mangan', 'Sehat', 'Virus Keriting' ], yticklabels=['Karat Putih', 'Kekurangan Mangan', 'Sehat', 'Virus Keriting'])\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9mrMHcsa2ap",
        "outputId": "c36a5fa7-c92b-4148-a01e-424b5da8eacc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Simpan model dalam format TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Mengaktifkan quantization\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Simpan model TFLite ke file\n",
        "tflite_model_file = 'model_self-made.tflite'\n",
        "with open(tflite_model_file, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "# Mengetahui ukuran model TFLite\n",
        "import os\n",
        "\n",
        "# Fungsi untuk mengonversi bytes ke megabytes\n",
        "def bytes_to_mb(size_in_bytes):\n",
        "    size_in_mb = size_in_bytes / (1024 * 1024)\n",
        "    return size_in_mb\n",
        "\n",
        "# Mengetahui ukuran model TFLite dalam bytes dan MB\n",
        "file_size_in_bytes = os.path.getsize(tflite_model_file)\n",
        "file_size_in_mb = bytes_to_mb(file_size_in_bytes)\n",
        "print(f\"Ukuran model TFLite setelah quantization: {file_size_in_bytes} bytes ({file_size_in_mb:.2f} MB)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7c8p06f-l_g"
      },
      "source": [
        "# 2. Transfer Learning using MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieT6zws85BtL",
        "outputId": "dc72fc43-2f60-4cb0-9a28-0ceb10c63a0e"
      },
      "outputs": [],
      "source": [
        "# Menggunakan MobileNetV2 untuk transfer learning\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load pre-trained MobileNetV2 tanpa lapisan atas\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(320, 320, 3))\n",
        "\n",
        "# Tambahkan lapisan baru di atasnya\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(4, activation='softmax')(x)  # Misal kita punya 4 kelas\n",
        "\n",
        "# Buat model baru\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze semua lapisan dari base_model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary to verify the configuration\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dpwPayst5Z40",
        "outputId": "1d356837-aa78-4b9e-c4bd-bd438f29bf1f"
      },
      "outputs": [],
      "source": [
        "# Visualisasi Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Menyimpan arsitektur model ke dalam file PNG\n",
        "plot_model(model, to_file='model_architecture_transfer_learning_mobilenetv2.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "# Menampilkan arsitektur model di notebook Colab\n",
        "from IPython.display import Image\n",
        "Image('model_architecture_transfer_learning_mobilenetv2.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5ND_jgu5cOS",
        "outputId": "4092a0a8-3572-4bc1-c74d-dd255b361882"
      },
      "outputs": [],
      "source": [
        "# Latih model dengan model.fit\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
        "    epochs=100,  # Tambahkan epochs jika akurasi model belum optimal\n",
        "    validation_data=validation_generator,  # Menampilkan akurasi pengujian data validasi\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
        "    # callbacks=[early_stopping],\n",
        "    verbose=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUSDNCqm5e-R",
        "outputId": "1f9c06b9-0cb3-4917-9a88-9c31e597cd77"
      },
      "outputs": [],
      "source": [
        "# Mengevaluasi model\n",
        "loss, accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // validation_generator.batch_size)\n",
        "print(\"Akurasi pada data validasi:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6f5lHZP5hr4",
        "outputId": "62f87d2a-24b8-4b00-cfa2-a96d3981708f"
      },
      "outputs": [],
      "source": [
        "print(history.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "xLbX3V7O5izP",
        "outputId": "8a48afdd-59ca-48bf-934b-e9f42c55d861"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot akurasi pelatihan dan validasi\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Menampilkan akurasi terakhir dari data validasi\n",
        "print(\"Akurasi terakhir:\", history.history['accuracy'][-1])\n",
        "print(\"Akurasi validasi terakhir:\", history.history['val_accuracy'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "PTRcCniUcKA7",
        "outputId": "53c156ef-7a62-4476-bf1e-090d6b4a6ade"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot loss pelatihan dan validasi\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Menampilkan loss terakhir dari data validasi\n",
        "print(\"Loss terakhir:\", history.history['loss'][-1])\n",
        "print(\"Loss validasi terakhir:\", history.history['val_loss'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4GYFL0B5mJN",
        "outputId": "e44c5ae8-2f69-4103-d125-adb4713fc089"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "\n",
        "# Perbaikan jumlah steps untuk memastikan semua sampel diproses\n",
        "steps = ceil(validation_generator_for_evaluation.samples / validation_generator_for_evaluation.batch_size)\n",
        "\n",
        "# Memprediksi seluruh data validasi dengan perbaikan steps\n",
        "predictions = model.predict(validation_generator_for_evaluation, steps=steps)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Mendapatkan label sebenarnya dari generator\n",
        "true_labels = validation_generator_for_evaluation.classes\n",
        "\n",
        "# Memastikan jumlah prediksi sama dengan label sebenarnya\n",
        "assert predicted_labels.shape[0] == true_labels.shape[0], \"Jumlah prediksi dan label sebenarnya harus sama.\"\n",
        "\n",
        "# Menghitung confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Menghitung metrik lain\n",
        "report = classification_report(true_labels, predicted_labels, target_names=validation_generator_for_evaluation.class_indices.keys())\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Menampilkan class indices\n",
        "class_indices = validation_generator_for_evaluation.class_indices\n",
        "print(\"Class indices:\", class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "7HZYVio55vk2",
        "outputId": "773a1832-c25e-43fe-9a1e-5f3c587cd71c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Menampilkan confusion matrix sebagai heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Karat Putih', 'Kekurangan Mangan', 'Sehat', 'Virus Keriting' ], yticklabels=['Karat Putih', 'Kekurangan Mangan', 'Sehat', 'Virus Keriting'])\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnmfl5hZazvn",
        "outputId": "e479a432-a0b2-4464-896c-c537d7813757"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Simpan model dalam format TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Mengaktifkan quantization\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Simpan model TFLite ke file\n",
        "tflite_model_file = 'model_MobileNetV2.tflite'\n",
        "with open(tflite_model_file, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "# Mengetahui ukuran model TFLite\n",
        "import os\n",
        "\n",
        "# Fungsi untuk mengonversi bytes ke megabytes\n",
        "def bytes_to_mb(size_in_bytes):\n",
        "    size_in_mb = size_in_bytes / (1024 * 1024)\n",
        "    return size_in_mb\n",
        "\n",
        "# Mengetahui ukuran model TFLite dalam bytes dan MB\n",
        "file_size_in_bytes = os.path.getsize(tflite_model_file)\n",
        "file_size_in_mb = bytes_to_mb(file_size_in_bytes)\n",
        "print(f\"Ukuran model TFLite setelah quantization: {file_size_in_bytes} bytes ({file_size_in_mb:.2f} MB)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJvzU9jVZVWH"
      },
      "source": [
        "# 3. Transfer Learning using InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUdN8-6GZa_Z",
        "outputId": "c64125fc-58f0-4815-cc6f-94fbec2be259"
      },
      "outputs": [],
      "source": [
        "# Menggunakan InceptionV3 untuk transfer learning\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load pre-trained InceptionV3 tanpa lapisan atas\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(320, 320, 3))\n",
        "\n",
        "# Tambahkan lapisan baru di atasnya\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(4, activation='softmax')(x)  # Misal kita punya 4 kelas\n",
        "\n",
        "# Buat model baru\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze semua lapisan dari base_model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary to verify the configuration\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZcOIMF_VZoCo",
        "outputId": "f6cd1915-43fa-409b-eef6-78d093e218de"
      },
      "outputs": [],
      "source": [
        "# Visualisasi Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Menyimpan arsitektur model ke dalam file PNG\n",
        "plot_model(model, to_file='model_architecture_inceptionV3.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "# Menampilkan arsitektur model di notebook Colab\n",
        "from IPython.display import Image\n",
        "Image('model_architecture_inceptionV3.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SSV65D-Zz3I",
        "outputId": "9866deef-eee4-407f-b566-c186551ac957"
      },
      "outputs": [],
      "source": [
        "# Latih model dengan model.fit\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
        "    epochs=100,  # Tambahkan epochs jika akurasi model belum optimal\n",
        "    validation_data=validation_generator,  # Menampilkan akurasi pengujian data validasi\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
        "    # callbacks=[early_stopping],\n",
        "    verbose=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWu0QnEXZ2Oi",
        "outputId": "f2c6cb4a-22c8-43ee-da8d-6a8b3c30c62f"
      },
      "outputs": [],
      "source": [
        "# Mengevaluasi model\n",
        "loss, accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // validation_generator.batch_size)\n",
        "print(\"Akurasi pada data validasi:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s0RzsqqZ5T9",
        "outputId": "c3bcde30-9eda-4622-c78c-55c27f893c42"
      },
      "outputs": [],
      "source": [
        "print(history.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "2dkWRJOgZ5sv",
        "outputId": "df7a6318-e7f6-43a0-bc20-dc366fd7b1c9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot akurasi pelatihan dan validasi\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Menampilkan akurasi terakhir dari data validasi\n",
        "print(\"Akurasi terakhir:\", history.history['accuracy'][-1])\n",
        "print(\"Akurasi validasi terakhir:\", history.history['val_accuracy'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "m7zOgSTxcUFU",
        "outputId": "58b5b4cb-ef8c-4572-b9d1-13d235c93191"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot loss pelatihan dan validasi\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Menampilkan loss terakhir dari data validasi\n",
        "print(\"Loss terakhir:\", history.history['loss'][-1])\n",
        "print(\"Loss validasi terakhir:\", history.history['val_loss'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGUXltqJZ7_N",
        "outputId": "d4ee5080-e305-4a5d-a16f-488e5aaa1919"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "\n",
        "# Perbaikan jumlah steps untuk memastikan semua sampel diproses\n",
        "steps = ceil(validation_generator_for_evaluation.samples / validation_generator_for_evaluation.batch_size)\n",
        "\n",
        "# Memprediksi seluruh data validasi dengan perbaikan steps\n",
        "predictions = model.predict(validation_generator_for_evaluation, steps=steps)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Mendapatkan label sebenarnya dari generator\n",
        "true_labels = validation_generator_for_evaluation.classes\n",
        "\n",
        "# Memastikan jumlah prediksi sama dengan label sebenarnya\n",
        "assert predicted_labels.shape[0] == true_labels.shape[0], \"Jumlah prediksi dan label sebenarnya harus sama.\"\n",
        "\n",
        "# Menghitung confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Menghitung metrik lain\n",
        "report = classification_report(true_labels, predicted_labels, target_names=validation_generator_for_evaluation.class_indices.keys())\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Menampilkan class indices\n",
        "class_indices = validation_generator_for_evaluation.class_indices\n",
        "print(\"Class indices:\", class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "KmuNC5HGaNHH",
        "outputId": "6058d173-d780-4e0c-ef59-d182bb50f761"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Menampilkan confusion matrix sebagai heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Karat Putih', 'Kekurangan Mangan', 'Sehat', 'Virus Keriting' ], yticklabels=['Karat Putih', 'Kekurangan Mangan', 'Sehat', 'Virus Keriting'])\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGV90jdKawmC",
        "outputId": "a494791e-dfef-4d40-cd3d-04116d58ef58"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Simpan model dalam format TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Mengaktifkan quantization\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Simpan model TFLite ke file\n",
        "tflite_model_file = 'model_InceptionV3.tflite'\n",
        "with open(tflite_model_file, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "# Mengetahui ukuran model TFLite\n",
        "import os\n",
        "\n",
        "# Fungsi untuk mengonversi bytes ke megabytes\n",
        "def bytes_to_mb(size_in_bytes):\n",
        "    size_in_mb = size_in_bytes / (1024 * 1024)\n",
        "    return size_in_mb\n",
        "\n",
        "# Mengetahui ukuran model TFLite dalam bytes dan MB\n",
        "file_size_in_bytes = os.path.getsize(tflite_model_file)\n",
        "file_size_in_mb = bytes_to_mb(file_size_in_bytes)\n",
        "print(f\"Ukuran model TFLite setelah quantization: {file_size_in_bytes} bytes ({file_size_in_mb:.2f} MB)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_ErbcalgmER"
      },
      "source": [
        "# 4. Transfer Learning using ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7pNcW8fgsDl",
        "outputId": "2b9f2474-1eed-473e-ff2b-b06e0461f0da"
      },
      "outputs": [],
      "source": [
        "# Menggunakan ResNet50 untuk transfer learning\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load pre-trained ResNet50 tanpa lapisan atas\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(320, 320, 3))\n",
        "\n",
        "# Tambahkan lapisan baru di atasnya\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(4, activation='softmax')(x)  # Misal kita punya 4 kelas\n",
        "\n",
        "# Buat model baru\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze semua lapisan dari base_model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary to verify the configuration\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWzWfX3BgyFg",
        "outputId": "3cad6f44-6aba-47de-ce78-6ab97d07d2fe"
      },
      "outputs": [],
      "source": [
        "# Visualisasi Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Menyimpan arsitektur model ke dalam file PNG\n",
        "plot_model(model, to_file='model_architecture_resnet50.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "# Menampilkan arsitektur model di notebook Colab\n",
        "from IPython.display import Image\n",
        "Image('model_architecture_resnet50.png')\n",
        "\n",
        "# Latih model dengan model.fit\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
        "    epochs=100,  # Tambahkan epochs jika akurasi model belum optimal\n",
        "    validation_data=validation_generator,  # Menampilkan akurasi pengujian data validasi\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
        "    verbose=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDFx6pAXg9D2",
        "outputId": "2d1afc8f-4cfd-4b96-d43a-744d971123ba"
      },
      "outputs": [],
      "source": [
        "# Mengevaluasi model\n",
        "loss, accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // validation_generator.batch_size)\n",
        "print(\"Akurasi pada data validasi:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK1jRV0Ag9f3",
        "outputId": "45048ec5-3754-4081-c10f-63c67d930365"
      },
      "outputs": [],
      "source": [
        "print(history.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "YcJh38p6g_Bi",
        "outputId": "aaf7dc5e-8703-4bff-b365-613d0cef8e2f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot akurasi pelatihan dan validasi\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Menampilkan akurasi terakhir dari data validasi\n",
        "print(\"Akurasi terakhir:\", history.history['accuracy'][-1])\n",
        "print(\"Akurasi validasi terakhir:\", history.history['val_accuracy'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "4d99hjy_hCvG",
        "outputId": "1fe58625-3cc1-4467-a6a0-50084d56400f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot loss pelatihan dan validasi\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Menampilkan loss terakhir dari data validasi\n",
        "print(\"Loss terakhir:\", history.history['loss'][-1])\n",
        "print(\"Loss validasi terakhir:\", history.history['val_loss'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdqcw9tnhIdA",
        "outputId": "20819975-1045-47f5-eab9-3d1c4dbd7978"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "\n",
        "# Perbaikan jumlah steps untuk memastikan semua sampel diproses\n",
        "steps = ceil(validation_generator_for_evaluation.samples / validation_generator_for_evaluation.batch_size)\n",
        "\n",
        "# Memprediksi seluruh data validasi dengan perbaikan steps\n",
        "predictions = model.predict(validation_generator_for_evaluation, steps=steps)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Mendapatkan label sebenarnya dari generator\n",
        "true_labels = validation_generator_for_evaluation.classes\n",
        "\n",
        "# Memastikan jumlah prediksi sama dengan label sebenarnya\n",
        "assert predicted_labels.shape[0] == true_labels.shape[0], \"Jumlah prediksi dan label sebenarnya harus sama.\"\n",
        "\n",
        "# Menghitung confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Menghitung metrik lain\n",
        "report = classification_report(true_labels, predicted_labels, target_names=validation_generator_for_evaluation.class_indices.keys())\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Menampilkan class indices\n",
        "class_indices = validation_generator_for_evaluation.class_indices\n",
        "print(\"Class indices:\", class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9trKyXOkhNN0",
        "outputId": "3d84c0b5-0ff7-412d-a5ff-2baeb4e21e1b"
      },
      "outputs": [],
      "source": [
        "# Mengubah model ke format TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Mengaktifkan quantization\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Simpan model TFLite ke file\n",
        "tflite_model_file = 'model_resnet50_quantized.tflite'\n",
        "with open(tflite_model_file, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "# Fungsi untuk mengonversi bytes ke megabytes\n",
        "def bytes_to_mb(size_in_bytes):\n",
        "    size_in_mb = size_in_bytes / (1024 * 1024)\n",
        "    return size_in_mb\n",
        "\n",
        "# Mengetahui ukuran model TFLite dalam bytes dan MB\n",
        "file_size_in_bytes = os.path.getsize(tflite_model_file)\n",
        "file_size_in_mb = bytes_to_mb(file_size_in_bytes)\n",
        "print(f\"Ukuran model TFLite setelah quantization: {file_size_in_bytes} bytes ({file_size_in_mb:.2f} MB)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvaS6USrhVET"
      },
      "source": [
        "# 5. Transfer Learning using DenseNet121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMm9QLpXhZs5",
        "outputId": "a82dbe95-a8e8-4939-b497-1d7db324cfdc"
      },
      "outputs": [],
      "source": [
        "# Menggunakan DenseNet121 untuk transfer learning\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load pre-trained DenseNet121 tanpa lapisan atas\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(320, 320, 3))\n",
        "\n",
        "# Tambahkan lapisan baru di atasnya\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(4, activation='softmax')(x)  # Misal kita punya 4 kelas\n",
        "\n",
        "# Buat model baru\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze semua lapisan dari base_model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary to verify the configuration\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nqTuNchphelS",
        "outputId": "65183d98-6673-4b56-ffe4-4dbd875ffa86"
      },
      "outputs": [],
      "source": [
        "# Visualisasi Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Menyimpan arsitektur model ke dalam file PNG\n",
        "plot_model(model, to_file='model_architecture_densenet121.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "# Menampilkan arsitektur model di notebook Colab\n",
        "from IPython.display import Image\n",
        "Image('model_architecture_densenet121.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK-S2CVLhg3G",
        "outputId": "94f5ab0e-2a95-424d-eaab-81f304e39acc"
      },
      "outputs": [],
      "source": [
        "# Latih model dengan model.fit\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
        "    epochs=100,  # Tambahkan epochs jika akurasi model belum optimal\n",
        "    validation_data=validation_generator,  # Menampilkan akurasi pengujian data validasi\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
        "    verbose=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbWT1jMlhkEi",
        "outputId": "5c0d60cb-0101-4bb3-d0c0-4a660cd63af0"
      },
      "outputs": [],
      "source": [
        "# Mengevaluasi model\n",
        "loss, accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // validation_generator.batch_size)\n",
        "print(\"Akurasi pada data validasi:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16Nv4_8Phk8Y",
        "outputId": "99b9311d-8590-4c44-b709-82efceee0787"
      },
      "outputs": [],
      "source": [
        "print(history.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "6ENHpgaZhmPw",
        "outputId": "7dae543e-5c4d-49a6-dd3f-cf701cf6e02e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot akurasi pelatihan dan validasi\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Menampilkan akurasi terakhir dari data validasi\n",
        "print(\"Akurasi terakhir:\", history.history['accuracy'][-1])\n",
        "print(\"Akurasi validasi terakhir:\", history.history['val_accuracy'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "FeIadyBMhoyc",
        "outputId": "fe93a8ac-7694-484c-bcfb-762492e138e4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot loss pelatihan dan validasi\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Menampilkan loss terakhir dari data validasi\n",
        "print(\"Loss terakhir:\", history.history['loss'][-1])\n",
        "print(\"Loss validasi terakhir:\", history.history['val_loss'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8olnxaeLhuJu",
        "outputId": "82936dc7-4692-4097-d795-a8f474d41643"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "\n",
        "# Perbaikan jumlah steps untuk memastikan semua sampel diproses\n",
        "steps = ceil(validation_generator_for_evaluation.samples / validation_generator_for_evaluation.batch_size)\n",
        "\n",
        "# Memprediksi seluruh data validasi dengan perbaikan steps\n",
        "predictions = model.predict(validation_generator_for_evaluation, steps=steps)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Mendapatkan label sebenarnya dari generator\n",
        "true_labels = validation_generator_for_evaluation.classes\n",
        "\n",
        "# Memastikan jumlah prediksi sama dengan label sebenarnya\n",
        "assert predicted_labels.shape[0] == true_labels.shape[0], \"Jumlah prediksi dan label sebenarnya harus sama.\"\n",
        "\n",
        "# Menghitung confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Menghitung metrik lain\n",
        "report = classification_report(true_labels, predicted_labels, target_names=validation_generator_for_evaluation.class_indices.keys())\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Menampilkan class indices\n",
        "class_indices = validation_generator_for_evaluation.class_indices\n",
        "print(\"Class indices:\", class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "VDY0DgxDsLPB",
        "outputId": "c4a3ec5f-4296-486f-dcf2-e3cb1038ff07"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Menampilkan confusion matrix sebagai heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Karat Putih', 'Kekurangan Mangan', 'Sehat', 'Virus Keriting' ], yticklabels=['Karat Putih', 'Kekurangan Mangan', 'Sehat', 'Virus Keriting'])\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCmqMNPDh0B_",
        "outputId": "5d85ec93-c901-471c-d7ce-31d0cbc0e2f6"
      },
      "outputs": [],
      "source": [
        "# Mengubah model ke format TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Mengaktifkan quantization\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Simpan model TFLite ke file\n",
        "tflite_model_file = 'model_densenet121_quantized.tflite'\n",
        "with open(tflite_model_file, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "# Fungsi untuk mengonversi bytes ke megabytes\n",
        "def bytes_to_mb(size_in_bytes):\n",
        "    size_in_mb = size_in_bytes / (1024 * 1024)\n",
        "    return size_in_mb\n",
        "\n",
        "# Mengetahui ukuran model TFLite dalam bytes dan MB\n",
        "file_size_in_bytes = os.path.getsize(tflite_model_file)\n",
        "file_size_in_mb = bytes_to_mb(file_size_in_bytes)\n",
        "print(f\"Ukuran model TFLite setelah quantization: {file_size_in_bytes} bytes ({file_size_in_mb:.2f} MB)\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
